# 🚀 Internship Task - 1: Big Data Analysis with Dask

## 📁 Project Title
**Titanic Survival Prediction using Dask**

## 🎯 Objective
The goal of this task is to analyze a large dataset using big data tools like **Dask** to demonstrate scalability, parallel processing, and efficient data handling.

## 📂 Dataset
**File Used**: `titanic.csv`  
This dataset contains records of Titanic passengers with information like gender, age, class, and survival status.

## 🧰 Tools & Technologies
- Python
- Dask (for big data processing)
- Jupyter Lab (for code and analysis)

## 📝 Key Steps Performed
- Loaded dataset using `dask.dataframe`
- Displayed dataset info (rows, columns, types)
- Handled missing values
- Calculated survival rate overall
- Calculated survival rate by gender
- Summarized passenger age statistics

## 📊 Sample Results
- Overall survival rate: _e.g._ **38.4%**
- Female survival rate: _e.g._ **74.2%**
- Male survival rate: _e.g._ **18.9%**
- Mean passenger age: _e.g._ **29.6 years**

## 📌 Deliverables
- `TITANIC_SURVIVAL_PREDICTION.ipynb`: Jupyter Notebook containing all code and output
- `README.md`: This file with project explanation

## ✅ Conclusion
This project demonstrates how Dask can efficiently handle and analyze large datasets with ease, showcasing its power and scalability. It also provides meaningful insights into the Titanic dataset, such as survival patterns by gender and age.
